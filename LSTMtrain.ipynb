{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amithpaul/LSTMPdM/blob/main/LSTMtrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSASNYKL6ave",
        "outputId": "fe09d163-8ca6-4e9d-c9b5-1cca3c8b90f0"
      },
      "outputs": [],
      "source": [
        "# prompt: import numpy as np\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# install libraries for these\n",
        "\n",
        "%pip install numpy tensorflow matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ulG9w0pp6rCH",
        "outputId": "c21b29e3-0468-461a-cb99-218e59537c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of loaded data: (22132, 49)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "# Clear the Keras session to reset the model's state\n",
        "K.clear_session()\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "# Load preprocessed dataset\n",
        "data = np.load(\"scaled_minmax.npy\").astype(np.float32)  # Ensure float32\n",
        "print(\"Shape of loaded data:\", data.shape)\n",
        "input_dim = data.shape[1]  # Number of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzV0QV2h7CbH"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "seq_length = 180  # Adjust based on your dataset\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequences.append(data[i : i + seq_length])\n",
        "    return np.array(sequences)\n",
        "\n",
        "X_train = create_sequences(data, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q1J69wg7E--"
      },
      "outputs": [],
      "source": [
        "# LSTM Autoencoder\n",
        "timesteps, features = X_train.shape[1], X_train.shape[2]\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(timesteps, features))\n",
        "masked_input = Masking(mask_value=-1)(input_layer)\n",
        "encoded = LSTM(64, activation=\"relu\", return_sequences=True, recurrent_dropout=0.2)(masked_input)\n",
        "encoded = LSTM(32, activation=\"relu\", return_sequences=True, recurrent_dropout=0.2)(encoded)\n",
        "\n",
        "decoded = Dense(64, activation=\"relu\")(encoded)\n",
        "decoded = Dense(features, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\",jit_compile=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naNHsLQU7IZq",
        "outputId": "6112e33f-8315-459b-8724-c3f9c087ac3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - loss: 0.0510 - val_loss: 0.0652\n",
            "Epoch 2/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 34ms/step - loss: 0.0091 - val_loss: 0.0280\n",
            "Epoch 3/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 0.0057 - val_loss: 0.0263\n",
            "Epoch 4/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0048 - val_loss: 0.0237\n",
            "Epoch 5/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0139\n",
            "Epoch 6/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0172\n",
            "Epoch 7/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0023 - val_loss: 0.0157\n",
            "Epoch 8/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0154\n",
            "Epoch 9/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0147\n",
            "Epoch 10/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 0.0152\n",
            "Epoch 11/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0018 - val_loss: 0.0155\n",
            "Epoch 12/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0017 - val_loss: 0.0153\n",
            "Epoch 13/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0148\n",
            "Epoch 14/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0151\n",
            "Epoch 15/100\n",
            "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78bef7b88350>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=200, batch_size=256,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HTrC6ME7KAd"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "autoencoder.save(\"lstm_autoencoderV2.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume 'history' is the output from model.fit()\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(X_test[0, :, 0], label=\"Actual\")  # First feature of a sample\n",
        "plt.plot(reconstructions[0, :, 0], label=\"Reconstructed\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPkisiUwXPmBKzY3n/sv8oN",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1nXTR9DcbvcAB0mA-knJJOMo4JwQ8zCou",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
